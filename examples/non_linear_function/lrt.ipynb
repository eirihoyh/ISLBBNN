{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import config\n",
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "path = \"C:\\\\Users\\\\eirik\\\\Documents\\\\Master\\\\ISLBBNN\\\\islbbnn\"\n",
    "# path = \"C:\\\\you\\\\path\\\\to\\\\islbbnn\\\\folder\\\\here\"\n",
    "os.chdir(path)\n",
    "import plot_functions as pf\n",
    "import pipeline_functions as pip_func\n",
    "sys.path.append('networks')\n",
    "from lrt_sigmoid_net import BayesianNetwork\n",
    "\n",
    "os.chdir(current_dir) # set the working directory back to this one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attain data\n",
    "\n",
    "Problem:\n",
    "\n",
    "$$y = x_1 + x_2 + x_1\\cdot x_2 + x_1^2 + x_2^2 + 100 +\\epsilon$$\n",
    "\n",
    "where $\\epsilon \\sim N(0,0.01)$. \n",
    "\n",
    "\n",
    "Can make $x_3$ dependent on $x_1$. The depedence is defined in the following way:\n",
    "\n",
    "\\begin{align*}\n",
    " x_1 &\\sim Unif(-10,10) \\\\\n",
    " x_3 &\\sim Unif(-10,10) \\\\\n",
    " x_3 &= \\text{dep}\\cdot x_1 + (1-\\text{dep})\\cdot x_3\n",
    "\\end{align*}\n",
    "\n",
    "## Pre process and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 4 10\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "HIDDEN_LAYERS = config['n_layers'] - 2 \n",
    "epochs = config['num_epochs']\n",
    "post_train_epochs = config['post_train_epochs']\n",
    "dim = config['hidden_dim']\n",
    "n_nets = config['n_nets']\n",
    "n_samples = config['n_samples']\n",
    "lr = config['lr']\n",
    "class_problem = config[\"class_problem\"]\n",
    "non_lin = config[\"non_lin\"]\n",
    "verbose = config['verbose']\n",
    "save_res = config['save_res']\n",
    "patience = config['patience']\n",
    "SAMPLES = 1\n",
    "\n",
    "\n",
    "# Get linear data, here a regression problem\n",
    "y, X = pip_func.create_data_unif(n_samples, beta=[100,1,1,1,1], dep_level=0.0, classification=class_problem, non_lin=non_lin)\n",
    "\n",
    "n, p = X.shape  # need this to get p \n",
    "print(n,p,dim)\n",
    "\n",
    "# Define BATCH sizes\n",
    "BATCH_SIZE = int((n*0.8)/100)\n",
    "TEST_BATCH_SIZE = int(n*0.10) # Would normally call this the \"validation\" part (will be used during training)\n",
    "VAL_BATCH_SIZE = int(n*0.10) # and this the \"test\" part (will be used after training)\n",
    "\n",
    "TRAIN_SIZE = int((n*0.80)/100)\n",
    "TEST_SIZE = int(n*0.10) # Would normally call this the \"validation\" part (will be used during training)\n",
    "VAL_SIZE = int(n*0.10) # and this the \"test\" part (will be used after training)\n",
    "\n",
    "NUM_BATCHES = TRAIN_SIZE/BATCH_SIZE\n",
    "\n",
    "print(NUM_BATCHES)\n",
    "\n",
    "assert (TRAIN_SIZE % BATCH_SIZE) == 0\n",
    "assert (TEST_SIZE % TEST_BATCH_SIZE) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate a test set for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split keep some of the data for validation after training\n",
    "X, X_test, y, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42)#, stratify=y)\n",
    "\n",
    "test_dat = torch.tensor(np.column_stack((X_test,y_test)),dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network\n",
    "\n",
    "## Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the device and initiate model\n",
    "\n",
    "# DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, validate and test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network 0\n",
      "54\n",
      "0\n",
      "loss 925.3873291015625\n",
      "nll 219.50637817382812\n",
      "density 0.9683086629267093\n",
      "\n",
      "val_loss: 3377.9114, val_nll: 2649.6443, val_ensemble: 0.6095, used_weights_median: 54\n",
      "\n",
      "1\n",
      "loss 458.15728759765625\n",
      "nll 152.3841094970703\n",
      "density 0.5228981839285957\n",
      "\n",
      "val_loss: 2052.9136, val_nll: 1764.6082, val_ensemble: 0.8468, used_weights_median: 22\n",
      "\n",
      "2\n",
      "loss 274.00311279296875\n",
      "nll 124.36599731445312\n",
      "density 0.26022213918191417\n",
      "\n",
      "val_loss: 1627.4569, val_nll: 1486.9828, val_ensemble: 0.8702, used_weights_median: 11\n",
      "\n",
      "3\n",
      "loss 244.03372192382812\n",
      "nll 108.3678970336914\n",
      "density 0.23993244667158084\n",
      "\n",
      "val_loss: 1452.2245, val_nll: 1319.9252, val_ensemble: 0.8800, used_weights_median: 11\n",
      "\n",
      "4\n",
      "loss 220.27041625976562\n",
      "nll 98.10523223876953\n",
      "density 0.216781132992495\n",
      "\n",
      "val_loss: 1354.3467, val_nll: 1234.6224, val_ensemble: 0.8798, used_weights_median: 10\n",
      "\n",
      "5\n",
      "loss 216.26412963867188\n",
      "nll 97.57791900634766\n",
      "density 0.2131863366122599\n",
      "\n",
      "val_loss: 1311.7034, val_nll: 1194.5437, val_ensemble: 0.8758, used_weights_median: 10\n",
      "\n",
      "6\n",
      "loss 208.8189697265625\n",
      "nll 91.44999694824219\n",
      "density 0.20980501834613582\n",
      "\n",
      "val_loss: 1269.1011, val_nll: 1152.1022, val_ensemble: 0.8785, used_weights_median: 10\n",
      "\n",
      "7\n",
      "loss 196.514404296875\n",
      "nll 87.00553894042969\n",
      "density 0.1917019544893669\n",
      "\n",
      "val_loss: 1220.9011, val_nll: 1112.2694, val_ensemble: 0.8792, used_weights_median: 10\n",
      "\n",
      "8\n",
      "loss 187.9372100830078\n",
      "nll 79.62657165527344\n",
      "density 0.19062176421802077\n",
      "\n",
      "val_loss: 1174.8000, val_nll: 1067.1691, val_ensemble: 0.8872, used_weights_median: 10\n",
      "\n",
      "9\n",
      "loss 180.5947265625\n",
      "nll 76.1675796508789\n",
      "density 0.1858587581233156\n",
      "\n",
      "val_loss: 1125.9484, val_nll: 1019.8238, val_ensemble: 0.8950, used_weights_median: 10\n",
      "\n",
      "10\n",
      "loss 173.28863525390625\n",
      "nll 75.94595336914062\n",
      "density 0.1710344589513692\n",
      "\n",
      "val_loss: 1073.6757, val_nll: 976.8043, val_ensemble: 0.9010, used_weights_median: 9\n",
      "\n",
      "11\n",
      "loss 174.71072387695312\n",
      "nll 78.13818359375\n",
      "density 0.17046815627556364\n",
      "\n",
      "val_loss: 1036.3481, val_nll: 940.1454, val_ensemble: 0.9042, used_weights_median: 9\n",
      "\n",
      "12\n",
      "loss 168.29127502441406\n",
      "nll 71.80947875976562\n",
      "density 0.17005306254011682\n",
      "\n",
      "val_loss: 994.3159, val_nll: 898.1290, val_ensemble: 0.9095, used_weights_median: 9\n",
      "\n",
      "13\n",
      "loss 166.01751708984375\n",
      "nll 70.20244598388672\n",
      "density 0.16972491713197627\n",
      "\n",
      "val_loss: 967.4055, val_nll: 871.9053, val_ensemble: 0.9135, used_weights_median: 9\n",
      "\n",
      "14\n",
      "loss 168.6499786376953\n",
      "nll 73.30537414550781\n",
      "density 0.16945381342278173\n",
      "\n",
      "val_loss: 940.3540, val_nll: 845.2180, val_ensemble: 0.9120, used_weights_median: 9\n",
      "\n",
      "15\n",
      "loss 161.3001708984375\n",
      "nll 66.60332489013672\n",
      "density 0.16922709554718393\n",
      "\n",
      "val_loss: 915.0349, val_nll: 820.5705, val_ensemble: 0.9137, used_weights_median: 9\n",
      "\n",
      "16\n",
      "loss 163.01174926757812\n",
      "nll 67.26045227050781\n",
      "density 0.1690341697141304\n",
      "\n",
      "val_loss: 904.3445, val_nll: 808.7226, val_ensemble: 0.9130, used_weights_median: 9\n",
      "\n",
      "17\n",
      "loss 164.53713989257812\n",
      "nll 69.63097381591797\n",
      "density 0.1688684528570674\n",
      "\n",
      "val_loss: 886.4371, val_nll: 791.7119, val_ensemble: 0.9147, used_weights_median: 9\n",
      "\n",
      "18\n",
      "loss 160.28131103515625\n",
      "nll 65.88143157958984\n",
      "density 0.16872488265464738\n",
      "\n",
      "val_loss: 865.0181, val_nll: 770.6985, val_ensemble: 0.9157, used_weights_median: 9\n",
      "\n",
      "19\n",
      "loss 157.46310424804688\n",
      "nll 63.163108825683594\n",
      "density 0.1685982821056516\n",
      "\n",
      "val_loss: 850.0265, val_nll: 755.8858, val_ensemble: 0.9197, used_weights_median: 9\n",
      "\n",
      "20\n",
      "loss 153.61837768554688\n",
      "nll 58.20523452758789\n",
      "density 0.16848710283348164\n",
      "\n",
      "val_loss: 844.0038, val_nll: 748.6542, val_ensemble: 0.9157, used_weights_median: 9\n",
      "\n",
      "21\n",
      "loss 152.4542236328125\n",
      "nll 57.51633834838867\n",
      "density 0.16838842665095366\n",
      "\n",
      "val_loss: 836.2681, val_nll: 741.4116, val_ensemble: 0.9170, used_weights_median: 9\n",
      "\n",
      "22\n",
      "loss 151.73941040039062\n",
      "nll 56.96861267089844\n",
      "density 0.16830033252740073\n",
      "\n",
      "val_loss: 815.5280, val_nll: 720.8108, val_ensemble: 0.9197, used_weights_median: 9\n",
      "\n",
      "23\n",
      "loss 155.00381469726562\n",
      "nll 60.08827209472656\n",
      "density 0.1682215749406842\n",
      "\n",
      "val_loss: 804.7040, val_nll: 709.8041, val_ensemble: 0.9205, used_weights_median: 9\n",
      "\n",
      "24\n",
      "loss 153.8560791015625\n",
      "nll 59.38047790527344\n",
      "density 0.16815102324148434\n",
      "\n",
      "val_loss: 794.5610, val_nll: 700.1196, val_ensemble: 0.9225, used_weights_median: 9\n",
      "\n",
      "25\n",
      "loss 152.84637451171875\n",
      "nll 57.37186813354492\n",
      "density 0.16808795780795022\n",
      "\n",
      "val_loss: 795.5674, val_nll: 700.1440, val_ensemble: 0.9197, used_weights_median: 9\n",
      "\n",
      "26\n",
      "loss 153.01602172851562\n",
      "nll 58.54736328125\n",
      "density 0.16803151257584062\n",
      "\n",
      "val_loss: 778.7712, val_nll: 684.3904, val_ensemble: 0.9245, used_weights_median: 9\n",
      "\n",
      "27\n",
      "loss 153.47262573242188\n",
      "nll 58.396728515625\n",
      "density 0.16798062977021025\n",
      "\n",
      "val_loss: 765.5338, val_nll: 670.4543, val_ensemble: 0.9285, used_weights_median: 9\n",
      "\n",
      "28\n",
      "loss 151.81442260742188\n",
      "nll 55.907676696777344\n",
      "density 0.16793485014716647\n",
      "\n",
      "val_loss: 757.8612, val_nll: 661.9940, val_ensemble: 0.9255, used_weights_median: 9\n",
      "\n",
      "29\n",
      "loss 154.1593780517578\n",
      "nll 58.545841217041016\n",
      "density 0.16789383740763664\n",
      "\n",
      "val_loss: 754.0379, val_nll: 658.4263, val_ensemble: 0.9253, used_weights_median: 9\n",
      "\n",
      "30\n",
      "loss 151.06434631347656\n",
      "nll 55.302032470703125\n",
      "density 0.1678569109132729\n",
      "\n",
      "val_loss: 748.2968, val_nll: 652.5294, val_ensemble: 0.9253, used_weights_median: 9\n",
      "\n",
      "31\n",
      "loss 148.2792205810547\n",
      "nll 52.28246307373047\n",
      "density 0.1678241558084092\n",
      "\n",
      "val_loss: 743.4782, val_nll: 647.4945, val_ensemble: 0.9250, used_weights_median: 9\n",
      "\n",
      "32\n",
      "loss 142.55282592773438\n",
      "nll 46.212608337402344\n",
      "density 0.16779519416040448\n",
      "\n",
      "val_loss: 725.5090, val_nll: 629.1796, val_ensemble: 0.9300, used_weights_median: 9\n",
      "\n",
      "33\n",
      "loss 149.07199096679688\n",
      "nll 52.473602294921875\n",
      "density 0.16776971580219213\n",
      "\n",
      "val_loss: 699.9209, val_nll: 603.3632, val_ensemble: 0.9353, used_weights_median: 9\n",
      "\n",
      "34\n",
      "loss 155.0629425048828\n",
      "nll 59.05045700073242\n",
      "density 0.16774827105001788\n",
      "\n",
      "val_loss: 693.2219, val_nll: 597.1356, val_ensemble: 0.9375, used_weights_median: 9\n",
      "\n",
      "35\n",
      "loss 145.8847198486328\n",
      "nll 48.516902923583984\n",
      "density 0.16773050771250078\n",
      "\n",
      "val_loss: 692.8810, val_nll: 595.5212, val_ensemble: 0.9325, used_weights_median: 9\n",
      "\n",
      "36\n",
      "loss 149.8500213623047\n",
      "nll 53.16708755493164\n",
      "density 0.16771651061814433\n",
      "\n",
      "val_loss: 683.2887, val_nll: 586.6268, val_ensemble: 0.9370, used_weights_median: 9\n",
      "\n",
      "37\n",
      "loss 151.3394317626953\n",
      "nll 53.91336441040039\n",
      "density 0.167706275440718\n",
      "\n",
      "val_loss: 676.6847, val_nll: 579.1927, val_ensemble: 0.9370, used_weights_median: 9\n",
      "\n",
      "38\n",
      "loss 145.8075408935547\n",
      "nll 48.09591293334961\n",
      "density 0.16769985674936497\n",
      "\n",
      "val_loss: 677.2930, val_nll: 579.5150, val_ensemble: 0.9365, used_weights_median: 9\n",
      "\n",
      "39\n",
      "loss 149.95033264160156\n",
      "nll 52.0929069519043\n",
      "density 0.16769745215397389\n",
      "\n",
      "val_loss: 661.1506, val_nll: 563.2897, val_ensemble: 0.9410, used_weights_median: 9\n",
      "\n",
      "40\n",
      "loss 142.92437744140625\n",
      "nll 45.85116195678711\n",
      "density 0.16769918391246055\n",
      "\n",
      "val_loss: 662.8080, val_nll: 565.7138, val_ensemble: 0.9367, used_weights_median: 9\n",
      "\n",
      "41\n",
      "loss 139.54547119140625\n",
      "nll 42.40843963623047\n",
      "density 0.16770506244992484\n",
      "\n",
      "val_loss: 671.8932, val_nll: 574.7514, val_ensemble: 0.9337, used_weights_median: 9\n",
      "\n",
      "42\n",
      "loss 144.23367309570312\n",
      "nll 46.83777618408203\n",
      "density 0.16771578332743417\n",
      "\n",
      "val_loss: 644.3940, val_nll: 546.9992, val_ensemble: 0.9425, used_weights_median: 9\n",
      "\n",
      "43\n",
      "loss 138.10350036621094\n",
      "nll 40.2321662902832\n",
      "density 0.16773151420757468\n",
      "\n",
      "val_loss: 672.2144, val_nll: 574.3117, val_ensemble: 0.9345, used_weights_median: 9\n",
      "\n",
      "44\n",
      "loss 138.9376220703125\n",
      "nll 41.96269607543945\n",
      "density 0.1677523140646776\n",
      "\n",
      "val_loss: 646.6741, val_nll: 549.7308, val_ensemble: 0.9390, used_weights_median: 9\n",
      "\n",
      "45\n",
      "loss 146.6140899658203\n",
      "nll 49.34122085571289\n",
      "density 0.16777924499210375\n",
      "\n",
      "val_loss: 629.8617, val_nll: 532.5352, val_ensemble: 0.9430, used_weights_median: 9\n",
      "\n",
      "46\n",
      "loss 138.981689453125\n",
      "nll 40.764869689941406\n",
      "density 0.16781231071649086\n",
      "\n",
      "val_loss: 626.4507, val_nll: 528.1658, val_ensemble: 0.9447, used_weights_median: 9\n",
      "\n",
      "47\n",
      "loss 139.31997680664062\n",
      "nll 41.41120529174805\n",
      "density 0.16785235982307414\n",
      "\n",
      "val_loss: 625.5125, val_nll: 527.5098, val_ensemble: 0.9450, used_weights_median: 9\n",
      "\n",
      "48\n",
      "loss 141.46572875976562\n",
      "nll 42.74321746826172\n",
      "density 0.16790016490321485\n",
      "\n",
      "val_loss: 619.8889, val_nll: 521.1680, val_ensemble: 0.9445, used_weights_median: 9\n",
      "\n",
      "49\n",
      "loss 134.48020935058594\n",
      "nll 36.03790283203125\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 616.3107, val_nll: 517.7920, val_ensemble: 0.9470, used_weights_median: 9\n",
      "\n",
      "50\n",
      "loss 133.968017578125\n",
      "nll 37.93340301513672\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 606.7943, val_nll: 510.8319, val_ensemble: 0.9473, used_weights_median: 9\n",
      "\n",
      "51\n",
      "loss 135.08132934570312\n",
      "nll 38.90229415893555\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 606.7382, val_nll: 510.5995, val_ensemble: 0.9465, used_weights_median: 9\n",
      "\n",
      "52\n",
      "loss 136.06997680664062\n",
      "nll 39.35504913330078\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 607.0468, val_nll: 510.3770, val_ensemble: 0.9453, used_weights_median: 9\n",
      "\n",
      "53\n",
      "loss 138.3214874267578\n",
      "nll 41.98580551147461\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 602.6186, val_nll: 506.2744, val_ensemble: 0.9495, used_weights_median: 9\n",
      "\n",
      "54\n",
      "loss 136.37779235839844\n",
      "nll 39.90162658691406\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 609.4250, val_nll: 512.9991, val_ensemble: 0.9445, used_weights_median: 9\n",
      "\n",
      "55\n",
      "loss 137.58277893066406\n",
      "nll 40.8757209777832\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 597.6552, val_nll: 501.0048, val_ensemble: 0.9490, used_weights_median: 9\n",
      "\n",
      "56\n",
      "loss 140.7447509765625\n",
      "nll 44.16550064086914\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 588.9463, val_nll: 492.4472, val_ensemble: 0.9553, used_weights_median: 9\n",
      "\n",
      "57\n",
      "loss 140.84872436523438\n",
      "nll 44.51412582397461\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 583.0679, val_nll: 486.8019, val_ensemble: 0.9505, used_weights_median: 9\n",
      "\n",
      "58\n",
      "loss 140.3464813232422\n",
      "nll 43.39317321777344\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 591.8976, val_nll: 494.9861, val_ensemble: 0.9490, used_weights_median: 9\n",
      "\n",
      "59\n",
      "loss 134.68536376953125\n",
      "nll 37.29311752319336\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 578.0916, val_nll: 480.7701, val_ensemble: 0.9497, used_weights_median: 9\n",
      "\n",
      "60\n",
      "loss 138.79153442382812\n",
      "nll 42.19522476196289\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 597.3843, val_nll: 500.7994, val_ensemble: 0.9460, used_weights_median: 9\n",
      "\n",
      "61\n",
      "loss 137.1681671142578\n",
      "nll 40.514892578125\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 571.1234, val_nll: 474.4966, val_ensemble: 0.9525, used_weights_median: 9\n",
      "\n",
      "62\n",
      "loss 136.99285888671875\n",
      "nll 39.92798614501953\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 571.8174, val_nll: 474.7987, val_ensemble: 0.9515, used_weights_median: 9\n",
      "\n",
      "63\n",
      "loss 134.6705780029297\n",
      "nll 38.369140625\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 576.6875, val_nll: 480.3188, val_ensemble: 0.9475, used_weights_median: 9\n",
      "\n",
      "64\n",
      "loss 135.14248657226562\n",
      "nll 37.26811218261719\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 570.5059, val_nll: 472.6619, val_ensemble: 0.9500, used_weights_median: 9\n",
      "\n",
      "65\n",
      "loss 138.1315155029297\n",
      "nll 41.33150100708008\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 564.2256, val_nll: 467.4039, val_ensemble: 0.9580, used_weights_median: 9\n",
      "\n",
      "66\n",
      "loss 132.00112915039062\n",
      "nll 35.21616744995117\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 562.2838, val_nll: 465.5374, val_ensemble: 0.9563, used_weights_median: 9\n",
      "\n",
      "67\n",
      "loss 140.78353881835938\n",
      "nll 43.611351013183594\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 562.2407, val_nll: 465.0483, val_ensemble: 0.9537, used_weights_median: 9\n",
      "\n",
      "68\n",
      "loss 133.123046875\n",
      "nll 36.28693389892578\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 552.6945, val_nll: 455.8518, val_ensemble: 0.9553, used_weights_median: 9\n",
      "\n",
      "69\n",
      "loss 140.72467041015625\n",
      "nll 43.93277359008789\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 550.5819, val_nll: 453.7317, val_ensemble: 0.9563, used_weights_median: 9\n",
      "\n",
      "70\n",
      "loss 134.78866577148438\n",
      "nll 37.06995391845703\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 559.6436, val_nll: 461.9384, val_ensemble: 0.9565, used_weights_median: 9\n",
      "\n",
      "71\n",
      "loss 137.94015502929688\n",
      "nll 40.4393424987793\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 549.2866, val_nll: 451.8565, val_ensemble: 0.9587, used_weights_median: 9\n",
      "\n",
      "72\n",
      "loss 141.32794189453125\n",
      "nll 43.550392150878906\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 551.0898, val_nll: 453.3707, val_ensemble: 0.9545, used_weights_median: 9\n",
      "\n",
      "73\n",
      "loss 136.75990295410156\n",
      "nll 39.123477935791016\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 551.2036, val_nll: 453.5739, val_ensemble: 0.9530, used_weights_median: 9\n",
      "\n",
      "74\n",
      "loss 136.31448364257812\n",
      "nll 38.60181427001953\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 542.1556, val_nll: 444.4599, val_ensemble: 0.9537, used_weights_median: 9\n",
      "\n",
      "75\n",
      "loss 135.0454559326172\n",
      "nll 37.280879974365234\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 537.5804, val_nll: 439.8315, val_ensemble: 0.9615, used_weights_median: 9\n",
      "\n",
      "76\n",
      "loss 138.5614471435547\n",
      "nll 40.570064544677734\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 536.6788, val_nll: 438.7680, val_ensemble: 0.9567, used_weights_median: 9\n",
      "\n",
      "77\n",
      "loss 132.0699005126953\n",
      "nll 33.46474075317383\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 543.9022, val_nll: 445.3054, val_ensemble: 0.9555, used_weights_median: 9\n",
      "\n",
      "78\n",
      "loss 140.40353393554688\n",
      "nll 42.23405838012695\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 546.0869, val_nll: 447.9755, val_ensemble: 0.9515, used_weights_median: 9\n",
      "\n",
      "79\n",
      "loss 140.30661010742188\n",
      "nll 42.03130340576172\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 534.9089, val_nll: 436.6160, val_ensemble: 0.9545, used_weights_median: 9\n",
      "\n",
      "80\n",
      "loss 136.6743621826172\n",
      "nll 39.0400390625\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 539.8492, val_nll: 442.2058, val_ensemble: 0.9553, used_weights_median: 9\n",
      "\n",
      "81\n",
      "loss 136.64720153808594\n",
      "nll 39.00173568725586\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 534.1160, val_nll: 436.4633, val_ensemble: 0.9580, used_weights_median: 9\n",
      "\n",
      "82\n",
      "loss 137.70379638671875\n",
      "nll 39.539085388183594\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 535.4920, val_nll: 437.3202, val_ensemble: 0.9547, used_weights_median: 9\n",
      "\n",
      "83\n",
      "loss 136.70143127441406\n",
      "nll 38.34749984741211\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 535.4540, val_nll: 437.1250, val_ensemble: 0.9557, used_weights_median: 9\n",
      "\n",
      "84\n",
      "loss 133.18450927734375\n",
      "nll 35.287254333496094\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 537.0781, val_nll: 439.2022, val_ensemble: 0.9525, used_weights_median: 9\n",
      "\n",
      "85\n",
      "loss 136.02090454101562\n",
      "nll 38.08290481567383\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 523.3663, val_nll: 425.4554, val_ensemble: 0.9567, used_weights_median: 9\n",
      "\n",
      "86\n",
      "loss 133.04270935058594\n",
      "nll 35.07741165161133\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 532.3264, val_nll: 434.3735, val_ensemble: 0.9563, used_weights_median: 9\n",
      "\n",
      "87\n",
      "loss 132.71163940429688\n",
      "nll 33.77079772949219\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 523.7269, val_nll: 424.8494, val_ensemble: 0.9583, used_weights_median: 9\n",
      "\n",
      "88\n",
      "loss 130.43051147460938\n",
      "nll 32.44955062866211\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 518.8295, val_nll: 420.8725, val_ensemble: 0.9593, used_weights_median: 9\n",
      "\n",
      "89\n",
      "loss 129.00978088378906\n",
      "nll 30.69417381286621\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 522.1754, val_nll: 423.9305, val_ensemble: 0.9583, used_weights_median: 9\n",
      "\n",
      "90\n",
      "loss 129.4031524658203\n",
      "nll 31.711912155151367\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 512.5355, val_nll: 414.8596, val_ensemble: 0.9617, used_weights_median: 9\n",
      "\n",
      "91\n",
      "loss 132.78997802734375\n",
      "nll 34.65547180175781\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 518.6385, val_nll: 420.5429, val_ensemble: 0.9573, used_weights_median: 9\n",
      "\n",
      "92\n",
      "loss 134.726318359375\n",
      "nll 35.106285095214844\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 518.7413, val_nll: 419.1508, val_ensemble: 0.9553, used_weights_median: 9\n",
      "\n",
      "93\n",
      "loss 131.80368041992188\n",
      "nll 32.2734489440918\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 513.8892, val_nll: 414.4412, val_ensemble: 0.9567, used_weights_median: 9\n",
      "\n",
      "94\n",
      "loss 136.82852172851562\n",
      "nll 38.4005241394043\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 512.2399, val_nll: 413.8414, val_ensemble: 0.9593, used_weights_median: 9\n",
      "\n",
      "95\n",
      "loss 135.8081512451172\n",
      "nll 37.103607177734375\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 510.5674, val_nll: 411.8975, val_ensemble: 0.9605, used_weights_median: 9\n",
      "\n",
      "96\n",
      "loss 138.7384796142578\n",
      "nll 40.056488037109375\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 519.9377, val_nll: 421.2290, val_ensemble: 0.9605, used_weights_median: 9\n",
      "\n",
      "97\n",
      "loss 136.84034729003906\n",
      "nll 38.07801818847656\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 506.5800, val_nll: 407.8636, val_ensemble: 0.9570, used_weights_median: 9\n",
      "\n",
      "98\n",
      "loss 133.34178161621094\n",
      "nll 33.92637252807617\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 511.3190, val_nll: 411.9421, val_ensemble: 0.9595, used_weights_median: 9\n",
      "\n",
      "99\n",
      "loss 134.99192810058594\n",
      "nll 36.45174789428711\n",
      "density 0.16795649651423986\n",
      "\n",
      "val_loss: 503.1813, val_nll: 404.6916, val_ensemble: 0.9627, used_weights_median: 9\n",
      "\n",
      "0.16666666 density median\n",
      "9.0 used weights median\n",
      "0.938625 ensemble full\n",
      "0.941975 ensemble median\n",
      "[0.938625, 0.16666666]\n"
     ]
    }
   ],
   "source": [
    "all_nets = {}\n",
    "metrics_several_runs = []\n",
    "metrics_median_several_runs = []\n",
    "for ni in range(n_nets):\n",
    "    post_train = False\n",
    "    print('network', ni)\n",
    "    # Initate network\n",
    "    torch.manual_seed(ni+42)\n",
    "    net = BayesianNetwork(dim, p, HIDDEN_LAYERS, classification=class_problem).to(DEVICE)\n",
    "    alphas = pip_func.get_alphas_numpy(net)\n",
    "    nr_weights = np.sum([np.prod(a.shape) for a in alphas])\n",
    "    print(nr_weights)\n",
    "\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    all_nll = []\n",
    "    all_loss = []\n",
    "\n",
    "    # Split into training and test set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=1/9, random_state=ni)#, stratify=y)\n",
    "            \n",
    "    train_dat = torch.tensor(np.column_stack((X_train,y_train)),dtype = torch.float32)\n",
    "    val_dat = torch.tensor(np.column_stack((X_val,y_val)),dtype = torch.float32)\n",
    "    \n",
    "    # Train network\n",
    "    counter = 0\n",
    "    highest_acc = 0\n",
    "    best_model = copy.deepcopy(net)\n",
    "    for epoch in range(epochs + post_train_epochs):\n",
    "        if verbose:\n",
    "            print(epoch)\n",
    "        nll, loss = pip_func.train(net, train_dat, optimizer, BATCH_SIZE, NUM_BATCHES, p, DEVICE, nr_weights, post_train=post_train)\n",
    "        nll_val, loss_val, ensemble_val = pip_func.val(net, val_dat, DEVICE, verbose=verbose, reg=(not class_problem))\n",
    "        if ensemble_val >= highest_acc:\n",
    "            counter = 0\n",
    "            highest_acc = ensemble_val\n",
    "            best_model = copy.deepcopy(net)\n",
    "        else:\n",
    "            counter += 1\n",
    "        \n",
    "        all_nll.append(nll)\n",
    "        all_loss.append(loss)\n",
    "\n",
    "        if epoch == epochs-1:\n",
    "            post_train = True   # Post-train --> use median model \n",
    "            for name, param in net.named_parameters():\n",
    "                for i in range(HIDDEN_LAYERS+1):\n",
    "                    #if f\"linears{i}.lambdal\" in name:\n",
    "                    if f\"linears.{i}.lambdal\" in name:\n",
    "                        param.requires_grad_(False)\n",
    "\n",
    "        if counter >= patience:\n",
    "            break\n",
    "        \n",
    "    all_nets[ni] = net \n",
    "    # Results\n",
    "    metrics, metrics_median = pip_func.test_ensemble(all_nets[ni], test_dat, DEVICE, SAMPLES=10, reg=(not class_problem)) # Test same data 10 times to get average \n",
    "    metrics_several_runs.append(metrics)\n",
    "    metrics_median_several_runs.append(metrics_median)\n",
    "    pf.run_path_graph(all_nets[ni], threshold=0.5, save_path=f\"path_graphs/lrt/prob/test{ni}\", show=verbose)\n",
    "\n",
    "if verbose:\n",
    "    print(metrics)\n",
    "m = np.array(metrics_several_runs)\n",
    "m_median = np.array(metrics_median_several_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Seems like val_nll and val_loss is the same, but this is not true. Fix this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for plotting weight magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.run_path_graph_weight(net, save_path=\"path_graphs/lrt/weight/temp\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.9000159e-03, 9.7776996e-04, 9.7243045e-04, 7.1462744e-04],\n",
       "        [1.0562978e-03, 1.8786686e-03, 1.8330807e-03, 2.5666223e-03],\n",
       "        [1.0000000e+00, 9.9999404e-01, 3.0152025e-04, 2.5752204e-04],\n",
       "        [7.9982483e-04, 7.6221547e-04, 8.2809562e-03, 3.4691701e-03],\n",
       "        [1.5113523e-03, 6.9436670e-04, 8.6942367e-04, 8.9786836e-04],\n",
       "        [1.3443066e-03, 7.3418405e-04, 9.5240952e-04, 8.4099185e-04],\n",
       "        [1.4998798e-03, 9.6966058e-04, 1.0888408e-03, 7.4326072e-04],\n",
       "        [4.0966843e-04, 9.9994969e-01, 3.7607978e-04, 4.1295847e-04],\n",
       "        [9.9755563e-03, 1.0411217e-03, 2.9606109e-03, 7.0231557e-03],\n",
       "        [3.8803008e-04, 1.0000000e+00, 3.3020217e-04, 3.1847859e-04]],\n",
       "       dtype=float32),\n",
       " array([[1.5701920e-04, 7.6811435e-04, 1.0000000e+00, 8.2615798e-04,\n",
       "         7.1956799e-04, 8.0848840e-04, 7.4273249e-04, 1.0000000e+00,\n",
       "         8.0727239e-04, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "         3.5897046e-04, 3.6562642e-04]], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip_func.get_alphas_numpy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.0308874e+00,  8.6741424e-01,  2.7092358e-02, -1.1303907e-03],\n",
       "        [ 2.3953363e-02, -2.8360793e-03,  3.4015826e-03, -3.4925495e-03],\n",
       "        [ 4.2224801e-01,  2.1433486e-01,  1.5572631e-02, -1.9895034e-03],\n",
       "        [ 3.2922179e-01,  8.5675091e-01,  9.6578622e-01, -8.2574207e-01],\n",
       "        [ 6.5951347e-01,  1.0355248e+00,  8.8233262e-02, -4.3807101e-01],\n",
       "        [-6.5660334e-01,  3.8346007e-01,  5.9250742e-02,  9.2551476e-01],\n",
       "        [-6.4604022e-02, -1.0967822e+00, -1.0869149e+00,  1.5684751e-01],\n",
       "        [ 2.0661561e-02, -6.1666161e-01, -1.4194698e-05,  5.8925105e-03],\n",
       "        [ 7.7836841e-01,  7.4955505e-01,  1.7783241e-02,  3.0547616e-03],\n",
       "        [-2.1044217e-02, -1.1262019e+00, -9.3743455e-04, -2.0147987e-04]],\n",
       "       dtype=float32),\n",
       " array([[ 8.0842662e-01,  6.9610514e-02,  4.2719688e+01,  2.1565706e-02,\n",
       "          3.1601645e-02,  3.3257671e-02,  2.4771078e-02, -1.6498758e+01,\n",
       "         -4.6596909e-04, -1.9760948e+01, -1.8349903e+00, -2.6289647e+00,\n",
       "         -9.5312879e-04,  1.3501082e-03]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip_func.weight_matrices_numpy(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
